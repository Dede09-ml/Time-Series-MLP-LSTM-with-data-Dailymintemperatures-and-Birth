{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 17 (Daily min temperature).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwzmSwfbQXCx"
      },
      "source": [
        "# Time-series Prediction using MLP & LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc2O7GY1bgA6"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOqn7KW8-C6y"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from datetime import datetime\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGY3aGW4RzGp"
      },
      "source": [
        "## Datetime parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flztV8Zm-a7M"
      },
      "source": [
        "def parser(x):\n",
        "\treturn datetime.strptime(x, '%Y-%m-%d')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COo4BUZ3R0le"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkXGN-UsRR6L",
        "outputId": "1c50f0bf-c411-4744-d384-308933eea8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/Dataset/daily-min-temperatures.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "\n",
        "dataset.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "1981-01-01    20.7\n",
              "1981-01-02    17.9\n",
              "1981-01-03    18.8\n",
              "1981-01-04    14.6\n",
              "1981-01-05    15.8\n",
              "Name: Temp, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phXvg72BR2S8"
      },
      "source": [
        "## Plot dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "807eB0iMQ14O",
        "outputId": "cb5fce49-dace-499e-d7ac-a2809c32f38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "dataset.plot()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlfKis3h-zqF"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HW27qy8R5EY"
      },
      "source": [
        "## Processing Time-series Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz0iDNHcRWOB"
      },
      "source": [
        "def timeseries_to_supervised(data, lag=1):\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
        "\tcolumns.append(df)\n",
        "\tdf = pd.concat(columns, axis=1)\n",
        "\treturn df\n",
        "\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = dataset[i] - dataset[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn pd.Series(diff)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNwnSUTIP_zp",
        "outputId": "fc4a01b1-d523-4ab2-821f-2132566bf23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "lag = 1\n",
        "\n",
        "raw_values = dataset.values\n",
        "diff_values = difference(raw_values, 1)\n",
        "\n",
        "diff_values"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      -2.8\n",
              "1       0.9\n",
              "2      -4.2\n",
              "3       1.2\n",
              "4       0.0\n",
              "       ... \n",
              "3644   -0.6\n",
              "3645   -0.4\n",
              "3646   -0.1\n",
              "3647    2.2\n",
              "3648   -2.7\n",
              "Length: 3649, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2z8Q4xYTkK7",
        "outputId": "1aca5012-56c6-4edc-cc27-81d3e391c59d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "supervised = timeseries_to_supervised(diff_values, lag)\n",
        "supervised"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.8</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9</td>\n",
              "      <td>-4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-4.2</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3644</th>\n",
              "      <td>1.7</td>\n",
              "      <td>-0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3645</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3646</th>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3647</th>\n",
              "      <td>-0.1</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3648</th>\n",
              "      <td>2.2</td>\n",
              "      <td>-2.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3649 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    0\n",
              "0     NaN -2.8\n",
              "1    -2.8  0.9\n",
              "2     0.9 -4.2\n",
              "3    -4.2  1.2\n",
              "4     1.2  0.0\n",
              "...   ...  ...\n",
              "3644  1.7 -0.6\n",
              "3645 -0.6 -0.4\n",
              "3646 -0.4 -0.1\n",
              "3647 -0.1  2.2\n",
              "3648  2.2 -2.7\n",
              "\n",
              "[3649 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9TijnkaT0Up",
        "outputId": "f0c018ea-dcdd-4d87-f181-93d7f558e8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "supervised_values = supervised.values[lag:,:]\n",
        "supervised_values"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.8,  0.9],\n",
              "       [ 0.9, -4.2],\n",
              "       [-4.2,  1.2],\n",
              "       ...,\n",
              "       [-0.4, -0.1],\n",
              "       [-0.1,  2.2],\n",
              "       [ 2.2, -2.7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtbPbDYBQqIz"
      },
      "source": [
        "split_percentage = 0.75\n",
        "\n",
        "train_size = int(split_percentage * len(supervised_values))\n",
        "\n",
        "train, test = supervised_values[0:train_size], supervised_values[train_size:len(supervised_values)]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWKByAZOWcIi"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1)) # Range hasil scaling menjadi angka diantara -1 hingga 1\n",
        "scaler = scaler.fit(train)\n",
        "\n",
        "train_scaled = scaler.transform(train)\n",
        "test_scaled = scaler.transform(test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcOyFWAOxU3U",
        "outputId": "67e1ee06-0334-4912-e586-a5f5d7242129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "train_scaled"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.11607143,  0.21428571],\n",
              "       [ 0.21428571, -0.24107143],\n",
              "       [-0.24107143,  0.24107143],\n",
              "       ...,\n",
              "       [-0.16071429,  0.375     ],\n",
              "       [ 0.375     ,  0.125     ],\n",
              "       [ 0.125     , -0.16071429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpdkWwehYH8n"
      },
      "source": [
        "# Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsJGBXaQQwFB",
        "outputId": "4916931f-3c21-4f54-8bcf-981fc3703f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "feature_train, label_train = train_scaled[:, 0:-1], train_scaled[:, -1]\n",
        "feature_test, label_test = test_scaled[:, 0:-1], test_scaled[:, -1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history = model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.0603\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.0565\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0560\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJuCimMs0Xlw",
        "outputId": "fb9fa0af-2adf-42c3-dd1b-4e9cfffe32d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "loss = model.evaluate(feature_test, label_test, verbose=2)\n",
        "\n",
        "print(\"Test loss:\", loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 - 0s - loss: 0.0560\n",
            "Test loss: 0.05596500635147095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aWV4RhuccBt"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgx1IuNdcfY6",
        "outputId": "bc278091-5b85-46eb-ee1c-41b3e8947cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "history_dataframe = pd.DataFrame(history.history)\n",
        "history_dataframe['epoch'] = history.epoch\n",
        "history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>0.060668</td>\n",
              "      <td>0.055944</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>0.060689</td>\n",
              "      <td>0.055944</td>\n",
              "      <td>330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>0.060709</td>\n",
              "      <td>0.055945</td>\n",
              "      <td>327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.060653</td>\n",
              "      <td>0.055945</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0.060672</td>\n",
              "      <td>0.055946</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>0.060682</td>\n",
              "      <td>0.056006</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.060696</td>\n",
              "      <td>0.056007</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.060908</td>\n",
              "      <td>0.056042</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.062512</td>\n",
              "      <td>0.056539</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.072217</td>\n",
              "      <td>0.060295</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "186  0.060668  0.055944    186\n",
              "330  0.060689  0.055944    330\n",
              "327  0.060709  0.055945    327\n",
              "37   0.060653  0.055945     37\n",
              "52   0.060672  0.055946     52\n",
              "..        ...       ...    ...\n",
              "662  0.060682  0.056006    662\n",
              "3    0.060696  0.056007      3\n",
              "2    0.060908  0.056042      2\n",
              "1    0.062512  0.056539      1\n",
              "0    0.072217  0.060295      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUuHpMPfchpG",
        "outputId": "064a4852-02eb-458d-cd14-8f586250613f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(history) # epoch vs loss graph"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkeaQDxbZHYI"
      },
      "source": [
        "# Deeper model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRjbIlSnZIVu",
        "outputId": "3baad5a8-5794-4e4c-f189-170872660a9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "deeper_model = Sequential()\n",
        "deeper_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "deeper_model.add(Dense(5, activation='relu'))\n",
        "deeper_model.add(Dense(1))\n",
        "deeper_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "deeper_model_history = deeper_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0655 - val_loss: 0.0561\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0549\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0548\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0547\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0547\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0546\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0546\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0546\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0546\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0546\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0546\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0546\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0546\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0546\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0546\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0547\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0546\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0544\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0544\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0544\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0546\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0547\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0544\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0544\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0545\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxksLfsjZlK2",
        "outputId": "8df1e64a-d59e-4507-c642-cf9bd1cf9b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "deeper_history_dataframe = pd.DataFrame(deeper_model_history.history)\n",
        "deeper_history_dataframe['epoch'] = deeper_model_history.epoch\n",
        "deeper_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>0.058991</td>\n",
              "      <td>0.054435</td>\n",
              "      <td>318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>0.059003</td>\n",
              "      <td>0.054438</td>\n",
              "      <td>594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>0.059040</td>\n",
              "      <td>0.054440</td>\n",
              "      <td>665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>0.059043</td>\n",
              "      <td>0.054440</td>\n",
              "      <td>669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>0.059023</td>\n",
              "      <td>0.054442</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>0.059015</td>\n",
              "      <td>0.054667</td>\n",
              "      <td>517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.059714</td>\n",
              "      <td>0.054698</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.059957</td>\n",
              "      <td>0.054801</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.060591</td>\n",
              "      <td>0.054944</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.065468</td>\n",
              "      <td>0.056111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "318  0.058991  0.054435    318\n",
              "594  0.059003  0.054438    594\n",
              "665  0.059040  0.054440    665\n",
              "669  0.059043  0.054440    669\n",
              "288  0.059023  0.054442    288\n",
              "..        ...       ...    ...\n",
              "517  0.059015  0.054667    517\n",
              "3    0.059714  0.054698      3\n",
              "2    0.059957  0.054801      2\n",
              "1    0.060591  0.054944      1\n",
              "0    0.065468  0.056111      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uv9EnMgt--_",
        "outputId": "9e355e2f-d11c-4620-9497-e0573e474836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_loss(deeper_model_history) # epoch vs loss graph"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqcjp3avYLgU"
      },
      "source": [
        "# Wider model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82rebSGUYNK2",
        "outputId": "ade6691a-297b-492e-ff7c-1c777cc21507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 50\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "wider_model = Sequential()\n",
        "wider_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "wider_model.add(Dense(1))\n",
        "wider_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "wider_model_history = wider_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0549\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0541\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0540\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0542\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0543\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0542\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0542\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0546\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0548\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0542\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0546\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0545\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0543\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0537\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0545\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0545\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0545\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0543\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0545\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0543\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0546\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0538\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0538\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0544\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0539\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0539\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0544\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0539\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0547\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0544\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0544\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0546\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0545\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmrJSX3NYYh5",
        "outputId": "97f6f8f9-c13d-4a7f-f3de-9746c54eb342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "wider_history_dataframe = pd.DataFrame(wider_model_history.history)\n",
        "wider_history_dataframe['epoch'] = wider_model_history.epoch\n",
        "wider_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.057997</td>\n",
              "      <td>0.053731</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.058041</td>\n",
              "      <td>0.053732</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0.058008</td>\n",
              "      <td>0.053742</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.057917</td>\n",
              "      <td>0.053743</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.057951</td>\n",
              "      <td>0.053750</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0.057610</td>\n",
              "      <td>0.054626</td>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.058188</td>\n",
              "      <td>0.054640</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>0.057312</td>\n",
              "      <td>0.054733</td>\n",
              "      <td>952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.058148</td>\n",
              "      <td>0.054774</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.061730</td>\n",
              "      <td>0.054924</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "56   0.057997  0.053731     56\n",
              "39   0.058041  0.053732     39\n",
              "59   0.058008  0.053742     59\n",
              "57   0.057917  0.053743     57\n",
              "96   0.057951  0.053750     96\n",
              "..        ...       ...    ...\n",
              "259  0.057610  0.054626    259\n",
              "41   0.058188  0.054640     41\n",
              "952  0.057312  0.054733    952\n",
              "28   0.058148  0.054774     28\n",
              "0    0.061730  0.054924      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwvqfkTkZ-aw"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NiKK3E-Z_Ke",
        "outputId": "9b6751fb-e788-4bc2-d09b-54504f1900f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "# Reshape menjadi (jumlah sample, time steps, jumlah feature)\n",
        "# Time steps: jumlah lag, gunakan default 1\n",
        "# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
        "feature_train_reshaped = np.reshape(feature_train, (feature_train.shape[0], 1, feature_train.shape[1]))\n",
        "feature_test_reshaped = np.reshape(feature_test, (feature_test.shape[0], 1, feature_test.shape[1]))\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, activation='relu', input_dim=feature_train.shape[1])) # 50 LSTM Block\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "lstm_model_history = lstm_model.fit(feature_train_reshaped, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test_reshaped, label_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0660 - val_loss: 0.0554\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0543\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.0539\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0541\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0543\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0544\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0544\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0544\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0545\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0544\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0537\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0537\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0537\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0537\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0537\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0543\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwE413j8bCIr",
        "outputId": "8d1660da-0afb-4c9f-aa10-80d7309a119d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "lstm_history_dataframe = pd.DataFrame(lstm_model_history.history)\n",
        "lstm_history_dataframe['epoch'] = lstm_model_history.epoch\n",
        "lstm_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>0.057817</td>\n",
              "      <td>0.053735</td>\n",
              "      <td>555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>0.057831</td>\n",
              "      <td>0.053742</td>\n",
              "      <td>572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0.057859</td>\n",
              "      <td>0.053743</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>0.057954</td>\n",
              "      <td>0.053749</td>\n",
              "      <td>507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>0.057790</td>\n",
              "      <td>0.053749</td>\n",
              "      <td>581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>0.058172</td>\n",
              "      <td>0.054390</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.058035</td>\n",
              "      <td>0.054399</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>0.058213</td>\n",
              "      <td>0.054430</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>0.058058</td>\n",
              "      <td>0.054494</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.066038</td>\n",
              "      <td>0.055432</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "555  0.057817  0.053735    555\n",
              "572  0.057831  0.053742    572\n",
              "500  0.057859  0.053743    500\n",
              "507  0.057954  0.053749    507\n",
              "581  0.057790  0.053749    581\n",
              "..        ...       ...    ...\n",
              "175  0.058172  0.054390    175\n",
              "41   0.058035  0.054399     41\n",
              "183  0.058213  0.054430    183\n",
              "217  0.058058  0.054494    217\n",
              "0    0.066038  0.055432      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjQM8Yvqdjrx",
        "outputId": "76af9cba-fd20-4ec2-a009-6f54c5b729e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(lstm_model_history)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u2W4DhQzFE6"
      },
      "source": [
        "BASELINE (loss : 0.060668, val_loss :\t0.055944, epochs :\t186)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deg24nn8zLiY"
      },
      "source": [
        "DEEPER MODEL(loss : 0.058991, val_loss :\t0.054435, epochs :\t318)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyRlMIyvzXSG"
      },
      "source": [
        "WIDER MODEL(loss : 0.057997, val_loss :\t0.053731, epochs :\t56)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuMG673kzXXc"
      },
      "source": [
        "LSTM(loss : 0.057817, val_loss :\t0.053735, epochs :\t555)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ALgWeT9zwnp"
      },
      "source": [
        "Kesimpulan : nilai val_loss terendah ada pada model wider, tidak jauh berbeda dengan LSTM. Sehingga kedua model ini merupakan model terbaik."
      ]
    }
  ]
}